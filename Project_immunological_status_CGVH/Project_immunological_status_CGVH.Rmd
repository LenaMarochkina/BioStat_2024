---
title: "Study of the predictive ability of immunological status and clustering features on the development of chronic graft-versus-host disease after allogeneic hematopoietic stem cell transplantation."
author: "Elena Marochkina"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, echo = TRUE)
```

```{r libraries}
library(dplyr)
library(stringr)
library(tidyr)
library(flextable)
library(officer)
library(tibble)
library(ggplot2)
library(reshape2)
library(pheatmap)
library(caret)
library(corrplot)
library(randomForestSRC)
library(survival)
library(Boruta)
```

# 1. Read and Clean Data

``` {r clean data}
# Read data and rename columns
df <- readxl::read_excel("./data/AI_Tcells_DB.xlsx") 

# Check duplicates
duplicates <- df %>%
  group_by(ID, Time_OS, cGVHD_time, Names) %>%
  filter(n() > 1) %>%
  ungroup()  

# Clean the data 
df_clean <- df %>%
  # Rename columns
  rename(
    Subject_ID = ID,
    Observation_Days_Count = Time_OS,
    cGVHD_Diagnosis_Day = cGVHD_time,
    Cell_Count = Abs_Value
  ) %>%
  mutate(
    # Add flag to indicate which patients experienced cGVHD
    cGVHD_flag = as.numeric(ifelse(!is.na(cGVHD_Diagnosis_Day), 1, 0)),
    Subject_ID = as.factor(Subject_ID),
    
    # Add blood test group 
    Blood_test_day = case_when(
      grepl('ДЕНЬ ХРРТПХ_ПЕР.КРОВЬ', df$Names) ~ "cGVHD",
      grepl('ДЕНЬ ХРРТПХ +', df$Names) ~ paste0(str_extract(df$Names, "(?<=\\+)\\d+(?=_)"), "_cGVHD"),
      TRUE ~ str_extract(df$Names, "(?<=\\+)\\d+(?=_)")
    ),
    
    # Create exact cell name
    Cell_name = str_extract(Names, "(?<=/).*")
  ) %>%
  select(-Names)

unify_cell_name <- function(cell_name, replacements) {
  cell_name_unified <- cell_name
  for (replacement in replacements) {
    old_value <- replacement[1]
    new_value <- replacement[2]
    
    old_value <- str_replace_all(old_value, "([\\+\\*\\?\\|\\(\\)\\[\\]\\{\\}\\^\\$\\.])", "\\\\\\1")
    cell_name_unified <- str_replace_all(cell_name_unified, old_value, new_value)
  }
  return(cell_name_unified)
}

replacements <- list(
  c("PD1", "PD-1"),
  c("СТАР2", "STAR2"),
  c("4", "CD4_"),
  c("CD4_+", "CD4+_"),
  c("8", "CD8_"),
  c("CD8_+", "CD8+_"),
  c("Th", "TH"),
  c("__", "_"),
  c("_ ", "_")
)

# Apply the function to dataframe
df_clean <- df_clean %>%
  mutate(
    Cell_name_unified = Cell_name,
    Cell_name_unified = unify_cell_name(Cell_name, replacements)
    )

# Check for duplicates for control 
duplicates <- df_clean %>%
  group_by(Subject_ID, Observation_Days_Count, cGVHD_Diagnosis_Day, cGVHD_flag, Blood_test_day, Cell_name) %>%
  filter(n() > 1) %>%
  ungroup() 

# Check the unique cells name 
unique_cells_name <- unique(df_clean$Cell_name_unified)
print(unique_cells_name)

rm(duplicates, replacements, unify_cell_name)
```

**Crucial steps:**

1. cGVHD Flag: Adds a flag (cGVHD_flag) to indicate if a patient experienced chronic GVHD (1 if cGVHD_Diagnosis_Day is not NA, otherwise 0).
2. Blood Test Timing: classifies the blood test timing into groups (e.g., cGVHD, +30_cGVHD).
3. Cell Name Parsing: Extracts the exact immune cell name from the Names column.
4. Defines a function unify_cell_name to standardize cell names using a list of replacements (e.g., PD1 -> PD-1, 4 -> CD4_).

## 1.1. Rearrange Data

```{r rearrange data}

# Check the number of unique days
unique_days <- unique(df_clean$Blood_test_day)
print(unique_days)

# Transform the dataframe
df_transformed <- df_clean %>%
  group_by(Subject_ID, Blood_test_day) %>% # Group by Subject and Day of Blood Test
  pivot_wider(
    id_cols = c(Subject_ID, Observation_Days_Count, cGVHD_Diagnosis_Day, cGVHD_flag, Blood_test_day), # Columns to retain as is
    names_from = Cell_name_unified, # New columns will be created from this column's values
    values_from = Cell_Count, # Populate new columns with values from this column
    values_fill = list(Cell_Count = NA) # Fill missing values with NA
  ) %>%
  ungroup()

# Check if in any cell contain more than 1 number
multi_value_cells <- apply(df_transformed, 2, function(column) {
  any(grepl(",", column, fixed = TRUE) | grepl(" ", column))
})

contains_multiple_values <- ifelse(any(multi_value_cells), "Yes", "No")
print(contains_multiple_values)

rm(unique_days, contains_multiple_values)
```
**Crucial steps:**

1. Reshape the data, creating separate columns for each combination of Cell_name_unified and Blood_test_day. Missing values are filled with NA.
2. Checks if any transformed cell contains multiple values 
3. Randomly selects a patient and compares their raw Cell_Count data.

# 1.2. Check for duplicates 

```{r duplicates}
df_transformed_without_duplicated <- df_transformed %>%
  select(-c(Blood_test_day, Observation_Days_Count, cGVHD_Diagnosis_Day, cGVHD_flag )) %>%
  distinct()

```

# 2. Descriptive Statistics

``` {r descriptive statistics}
# Prepare df_transformed
df_transformed <- df_transformed %>%
  mutate(
    Subject_ID = as.factor(Subject_ID),
    cGVHD_flag = as.factor(cGVHD_flag)
  )

# List of descriptive statistics
statistics <- list(
  `Number of values` = ~as.character(sum(!is.na(.x))),
  `No data` = ~as.character(sum(is.na(.x))),
  `Mean` = ~ifelse(sum(!is.na(.x)) == 0, "NA", as.character(mean(.x, na.rm = TRUE) %>% round(2))),
  `Median` = ~ifelse(sum(!is.na(.x)) == 0, "NA", as.character(median(.x, na.rm = TRUE) %>% round(2))),
  `SD` = ~ifelse(sum(!is.na(.x)) < 3, "NA", as.character(sd(.x, na.rm = TRUE) %>% round(2))),
  `min` = ~ifelse(sum(!is.na(.x)) == 0, "NA", as.character(min(.x, na.rm = TRUE) %>% round(2))),
  `max` = ~ifelse(sum(!is.na(.x)) == 0, "NA", as.character(max(.x, na.rm = TRUE) %>% round(2)))
)

# Summarize the statistics for each numeric variable and make variables into columns
df_summary <- df_transformed %>%
  select(where(is.numeric)) %>%
  summarise(across(everything(), statistics, .names = "{.col}__{.fn}")) %>%
  pivot_longer(cols = everything(), names_sep = "__", names_to = c("Variable", "Stat"), values_to = "Value") %>%
  pivot_wider(names_from = Stat, values_from = Value) %>%
  slice(1:25)

# Create a flextable for the summary
flextable(df_summary) %>%
  autofit() %>%
  border_inner(border = fp_border(color = "black", width = 1)) %>%
  border_outer(border = fp_border(color = "black", width = 1))

# Clean and summarize the categorical data for all factor variables
df_transformed %>%
  select(-Subject_ID) %>%
  select(where(is.factor)) %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Value") %>%
  group_by(Variable, Value) %>%
  summarise(n = n(), .groups = 'drop') %>%
  group_by(Variable) %>%
  mutate(`No data` = sum(is.na(Value)),
         `% by group` = (n / sum(n)) * 100) %>%
  ungroup() %>%
  select(Variable, Value, n, `% by group`, `No data`) %>%
  arrange(Variable, Value) %>%
  flextable() %>%
  merge_v("Variable") %>%
  autofit() %>%
  border_inner(border = fp_border(color = "black", width = 1)) %>%
  border_outer(border = fp_border(color = "black", width = 1))

rm(df_summary, statistics)
```

The resulting table is too large and complex for effective understanding due to the number of numeric variables, but it highlights a high proportion of missing data (NA values).

# 3. Prediction of cGVHD outcome
## 3.1. Define DataSet

Survival Analysis are planned. 

*Event:* Diagnosis of cGVHD (cGVHD_flag == 1).

*Survival Time:*

- For patients with cGVHD: cGVHD_Diagnosis_Day as the survival time.
- For patients without cGVHD: Observation_Days_Count as the censored survival time.

*Perform PCA to reduce 167 variables into fewer components that explain the maximum variance!*

``` {r define dataset Prediction of cGVHD outcome}

# Select days of interest
df_cGVHD_prediction <- df_transformed %>%
  filter(Blood_test_day %in% c("90", "180", "365", "cGVHD")) 

# df_cGVHD_prediction <- df_cGVHD_prediction %>%
# # Apply log transformation to numeric columns
#  mutate(
#     Observation_Days_Count = factor(Observation_Days_Count),
#     cGVHD_Diagnosis_Day = factor(cGVHD_Diagnosis_Day)
#   ) %>%
#   mutate(across(
#     where(is.numeric), 
#     ~ log10(. + 1), 
#     .names = "{col}"
#   )) %>%
#   mutate(
#     Observation_Days_Count = as.numeric(Observation_Days_Count),
#     cGVHD_Diagnosis_Day = as.numeric(cGVHD_Diagnosis_Day)
#   )
```

**Crucial steps:**

1. The dataset (df_cGVHD_prediction) includes immune cell measurements at specific time points (_30, _60, _90, _180, _365, and _cGVHD) while excluding those associated with timing after chronic GVHD (e.g., _90_cGVHD).


## 3.2. Check for Missing Data

```{r check for missing data}
# Calculate missing values by Blood_test_day
missing_summary <- df_cGVHD_prediction %>%
  group_by(Blood_test_day) %>%
  summarise(across(everything(), ~ mean(is.na(.)) * 100)) %>%
  pivot_longer(cols = -Blood_test_day, names_to = "Column", values_to = "Missing_Percentage")
```

**Crucial steps:**

1. No missing values by Blood test day were identified for any cell name.

## 3.3. Visualisation
### 3.3.1. Correlation martrix

```{r correlation matrix}
# Select relevant numeric columns 
correlation_data <- df_cGVHD_prediction %>%
  filter(Blood_test_day %in% c("90")) %>%
  select(where(is.numeric))

# Compute correlation matrix
cor_matrix <- cor(correlation_data, use = "complete.obs")

# Mask weak correlations
cor_matrix[abs(cor_matrix) < 0.5] <- NA

# Plot only strong correlations
corrplot(cor_matrix, 
         method = "color", 
         type = "lower", 
         tl.col = "black", 
         tl.srt = 45, 
         number.cex = 0.1, 
         addCoef.col = "black", 
         mar = c(2, 2, 2, 2),
         cl.cex = 0.5,        
         tl.cex = 0.15)

# Create a table with corellation >= 0.9 as Variable1 variable 2 correlation coefficient
# Correlation matrix into a long format
correlation_table <- as.data.frame(as.table(cor_matrix))

# Rename the columns
colnames(correlation_table) <- c("Variable1", "Variable2", "Correlation")

# Filter for correlations >= 0.9
filtered_table <- correlation_table %>%
  filter(Correlation >= 0.9 & Variable1 != Variable2)

# Ensure no duplicate pairs by sorting Variable1 and Variable2
filtered_table <- filtered_table %>%
  mutate(
    Pair = paste0(pmin(Variable1, Variable2), "-", pmax(Variable1, Variable2))) %>%
  distinct(Pair, .keep_all = TRUE) %>%
  select(-Pair) %>%
  arrange(desc(Correlation)) %>%
  mutate(Num = row_number())

print(filtered_table)

# Check correlations for 'cGVHD_Diagnosis_Day' greater than 0.6
cgvhd_filtered_table <- correlation_table %>%
  filter(
    (Variable1 == "cGVHD_Diagnosis_Day") &
    Correlation > 0.6 & 
    (Variable1 != Variable2)
  ) %>%
  arrange(desc(Correlation)) %>%
  mutate(Num = row_number())

# Print the filtered table
print(cgvhd_filtered_table)

```

- In linear regression or logistic regression, multicollinearity makes it difficult to determine the unique contribution of each predictor variable.

Models that are not sensitive to multicollinearity because they split the data hierarchically:

- *Random Forest:* 
- *XGBoost*

### 3.3.2. Heatmap with clusters

```{r visualisation heatmap with clusters all data}

# Select relevant numeric columns 
correlation_data <- df_cGVHD_prediction %>%
  filter(Blood_test_day %in% c("90")) %>%
  select(where(is.numeric), -cGVHD_Diagnosis_Day)

# Compute correlation matrix
cor_matrix <- cor(correlation_data, use = "complete.obs")

# Hierarchical clustering and heatmap
pheatmap(cor_matrix,
         cluster_rows = TRUE,
         cluster_cols = TRUE,
         display_numbers = FALSE,
         fontsize_row = 2,
         fontsize_col = 2,
         main = "Clustered Heatmap for Survival Variables",
         width = 20, 
        height = 20  )


# Perform hierarchical clustering
# Convert correlation to distance
distance_matrix <- as.dist(1 - cor_matrix) 
hclust_result <- hclust(distance_matrix, method = "ward.D2") # Ward's method

# Cut the dendrogram into clusters (replace 5 with your desired number of clusters)
clusters <- cutree(hclust_result, k = 6) # Extract 5 clusters

# Create a data frame to associate variables with their clusters
clustered_data <- data.frame(
  Variable = rownames(cor_matrix),
  Cluster = clusters
)

# Dendrogram with clusters
plot(hclust_result, labels = rownames(cor_matrix), main = "Dendrogram of Clusters", cex = 0.2)

# Add rectangles to highlight clusters
rect.hclust(hclust_result, k = 5, border = 2:6)

```


```{r }
custom_order <- c("90", "180", "365", "cGVHD")

# Convert Blood_test_day to a factor with the custom order
df_cGVHD_transformed <- df_cGVHD_prediction %>%
  mutate(Blood_test_day = factor(Blood_test_day, levels = custom_order))

# Arrange data by the specified order of Blood_test_day
df_cGVHD_transformed <- df_cGVHD_transformed %>%
  arrange(Blood_test_day)

# Aggregate data by Blood_test_day
heatmap_data <- df_cGVHD_transformed %>%
  group_by(Blood_test_day) %>%
  summarise(across(where(is.numeric), mean, na.rm = TRUE)) %>%
  ungroup()

# Convert to matrix for heatmap plotting
heatmap_matrix <- heatmap_data %>%
  column_to_rownames("Blood_test_day") %>%
  as.matrix()

# Create the heatmap
pheatmap(heatmap_matrix,
         cluster_rows = FALSE,
         cluster_cols = TRUE,
         display_numbers = FALSE,
         fontsize_row = 6,
         fontsize_col = 3,
         main = "Heatmap: Variable Distribution by Blood Test Day")

```

Some variable distributions seem to change over time (Blood Test Day), with certain groups (e.g., those in warmer tones) showing higher activity at specific days, such as 365 (for non-log-transformed data).


### 3.3.3. PCA

```{r PCA}
# Filter and normalize data while preserving cGVHD_flag
df_normalized <- df_transformed %>%
  filter(Blood_test_day %in% c("90", "180", "365", "cGVHD")) %>%
  # Ensure cGVHD_flag is retained for later use
  select(cGVHD_flag, where(is.numeric), -Observation_Days_Count, -cGVHD_Diagnosis_Day) %>%
  mutate(across(where(is.numeric), ~ (.-mean(.)) / sd(.), .names = "z_{col}"))

# Save cGVHD_flag for later use
cGVHD_flags <- df_normalized$cGVHD_flag

# Perform near-zero variance filtering (excluding cGVHD_flag)
nzv <- nearZeroVar(df_normalized %>% select(-cGVHD_flag))
df_filtered <- df_normalized %>%
  select(-nzv, cGVHD_flag) %>% # Retain cGVHD_flag after filtering
  filter(complete.cases(.))

# Perform PCA (exclude cGVHD_flag from PCA computation)
pca_results <- prcomp(df_filtered %>% select(-cGVHD_flag), scale. = TRUE)

# Attach PCA scores and cGVHD_flag back together
pca_scores <- as.data.frame(pca_results$x) %>%
  mutate(cGVHD_flag = cGVHD_flags)

# Explained variance calculations
explained_variance <- pca_results$sdev^2 / sum(pca_results$sdev^2)
cumulative_variance <- cumsum(explained_variance)

# Create a data frame for plotting explained variance
explained_variance_data <- data.frame(
  PC = 1:length(explained_variance),
  Explained_Variance = explained_variance,
  Cumulative_Variance = cumulative_variance
)

# Filter for components contributing to the first 80% of cumulative variance
explained_variance_data_filtered <- explained_variance_data %>%
  filter(Cumulative_Variance <= 0.8)

# Add percentage labels for explained variance
explained_variance_data_filtered <- explained_variance_data_filtered %>%
  mutate(Variance_Percentage_Label = paste0(round(Explained_Variance * 100, 2), "%"))

# Plot explained variance with percentage labels
ggplot(explained_variance_data_filtered, aes(x = PC)) +
  geom_bar(aes(y = Explained_Variance), stat = "identity", fill = "steelblue") +
  geom_text(aes(y = Explained_Variance, label = Variance_Percentage_Label), 
            vjust = -0.5, size = 3.5) +
  geom_line(aes(y = Cumulative_Variance), color = "red", size = 1) +
  geom_point(aes(y = Cumulative_Variance), color = "red", size = 2) +
  scale_y_continuous(
    name = "Variance Explained",
    sec.axis = sec_axis(~., name = "Cumulative Variance Explained")
  ) +
  labs(
    title = "Explained Variance by Principal Components (First 80%)",
    x = "Principal Component"
  ) +
  theme_minimal(base_size = 14)
# Perform clustering on PCA scores
set.seed(123)
wss <- sapply(1:10, function(k) {
  kmeans(pca_scores[, 1:10], centers = k, nstart = 25)$tot.withinss
})

# Plot Elbow Method
elbow_plot <- data.frame(Clusters = 1:10, WSS = wss)
ggplot(elbow_plot, aes(x = Clusters, y = WSS)) +
  geom_line() +
  geom_point(size = 3) +
  labs(
    title = "Elbow Method for Optimal Clusters",
    x = "Number of Clusters",
    y = "Total Within-Cluster Sum of Squares (WSS)"
  ) +
  theme_minimal(base_size = 14)

# Apply K-means clustering
optimal_clusters <- 4
kmeans_result <- kmeans(pca_scores[, 1:10], centers = optimal_clusters, nstart = 25)
pca_scores$Cluster <- as.factor(kmeans_result$cluster)

# Visualize clusters with coloring by cGVHD_flag
ggplot(pca_scores, aes(x = PC1, y = PC2, color = as.factor(cGVHD_flag))) +
  geom_point(size = 2, alpha = 0.8) +  # Scatterplot of PCA points
  stat_ellipse(aes(group = Cluster), type = "t", linetype = "dashed", size = 1, color = "black") +  # Ellipses for clusters
  scale_color_brewer(palette = "Set1") +  # Color palette for cGVHD_flag
  labs(
    title = "PCA Clusters with cGVHD_flag Coloring and Cluster Ellipses",
    x = "PC1 (Principal Component 1)",
    y = "PC2 (Principal Component 2)",
    color = "cGVHD_flag"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "bottom",
    plot.title = element_text(face = "bold", hjust = 0.5)
  )


```

### 3.3.4. BORUTA algorithm
#### 3.3.4.1.   90 days

```{r Boruta 90 days}

df_normalized <- df_transformed %>%
  filter(Blood_test_day %in% c("90")) %>%
  filter(cGVHD_Diagnosis_Day > 90 | is.na(cGVHD_Diagnosis_Day)) %>%
  select(-Observation_Days_Count, -cGVHD_Diagnosis_Day, -Blood_test_day, )

# Apply the Boruta algorithm for feature selection
boruta_result_90 <- Boruta(cGVHD_flag ~ ., data = df_normalized)

final_decision <- attStats(boruta_result_90)
print(final_decision)

# Extract important variables
important_vars_90 <- getSelectedAttributes(boruta_result_90, withTentative = FALSE)

# Extract tentative variables
tentative_vars_90 <- getSelectedAttributes(boruta_result_90, withTentative = TRUE)
only_tentative_90 <- setdiff(tentative_vars_90, important_vars_90)

cat("Confirmed important variables:\n", paste(important_vars_90, collapse = ", "), "\n\n")
cat("Tentative variables:\n", paste(only_tentative_90, collapse = ", "), "\n")
```

#### 3.3.4.2.   180 days

```{r Boruta 180 days}

df_normalized <- df_transformed %>%
  filter(Blood_test_day %in% c("180")) %>%
  filter(cGVHD_Diagnosis_Day > 180 | is.na(cGVHD_Diagnosis_Day)) %>%
  select(-Observation_Days_Count, -cGVHD_Diagnosis_Day, -Blood_test_day, )

# Apply the Boruta algorithm for feature selection
boruta_result_180 <- Boruta(cGVHD_flag ~ ., data = df_normalized)

final_decision <- attStats(boruta_result_180)
print(final_decision)

# Extract important variables
important_vars_180 <- getSelectedAttributes(boruta_result_180, withTentative = FALSE)

# Extract tentative variables
tentative_vars_180 <- getSelectedAttributes(boruta_result_180, withTentative = TRUE)
only_tentative_180 <- setdiff(tentative_vars_180, important_vars_180)

cat("Confirmed important variables:\n", paste(important_vars_180, collapse = ", "), "\n\n")
cat("Tentative variables:\n", paste(only_tentative_180, collapse = ", "), "\n")
```

#### 3.3.4.3.   365 days

```{r Boruta 365 days}
df_normalized <- df_transformed %>%
  filter(Blood_test_day %in% c("365")) %>%
  filter(cGVHD_Diagnosis_Day > 365 | is.na(cGVHD_Diagnosis_Day)) %>%
  select(-Observation_Days_Count, -cGVHD_Diagnosis_Day, -Blood_test_day, )

# Apply the Boruta algorithm for feature selection
boruta_result_365 <- Boruta(cGVHD_flag ~ ., data = df_normalized)

final_decision <- attStats(boruta_result_365)
print(final_decision)

# Extract important variables
important_vars_365 <- getSelectedAttributes(boruta_result_365, withTentative = FALSE)

# Extract tentative variables
tentative_vars_365 <- getSelectedAttributes(boruta_result_365, withTentative = TRUE)
only_tentative_365 <- setdiff(tentative_vars_365, important_vars_365)

cat("Confirmed important variables:\n", paste(important_vars_365, collapse = ", "), "\n\n")
cat("Tentative variables:\n", paste(only_tentative_365, collapse = ", "), "\n")

```

```{r }

# Function to evaluate OOB Requested performance error for different numbers of trees
evaluate_trees <- function(data, formula, max_trees = 1000, step = 50) {
  results <- data.frame(Trees = integer(), OOB_Error = numeric())
  
  for (ntree in seq(50, max_trees, by = step)) {
    set.seed(123)  # Ensure reproducibility
    rf_model <- rfsrc(
      formula = formula,
      data = data,
      mtry = round(sqrt(ncol(data) - 2)),
      nodesize = 15,
      ntree = ntree,  # Number of trees
      importance = TRUE
    )
    
    # Extract the OOB Requested performance error
    oob_error <- rf_model$err.rate[length(rf_model$err.rate)]
    results <- rbind(results, data.frame(
      Trees = ntree,
      OOB_Error = oob_error
    ))
  }
  
  return(results)
}

# Apply the function to your dataset
oob_results <- evaluate_trees(
  data = dataSet,  # Replace with your dataset
  formula = Surv(cGVHD_Diagnosis_Day, cGVHD_flag) ~ .,
  max_trees = 1000,
  step = 50
)

ggplot(oob_results, aes(x = Trees, y = OOB_Error)) +
  geom_line() +
  geom_point(size = 2) +
  labs(
    title = "OOB Requested Performance Error vs. Number of Trees",
    x = "Number of Trees",
    y = "OOB Requested Performance Error"
  ) +
  theme_minimal()

# Find the number of trees with the minimum OOB error
best_trees <- oob_results$Trees[which.min(oob_results$OOB_Error)]

print(paste("Best number of trees:", best_trees))
```

```{r RFS 90 days}
# Build the Random Survival Forest model
RF_obj <- rfsrc(Surv(cGVHD_Diagnosis_Day,cGVHD_flag)~.,
                dataSet,
                ntree = best_trees,
                mtry = round(sqrt(ncol(dataSet) - 2)),
                nodesize = 15,
                membership = TRUE,
                importance=TRUE)

# Print the Random Survival Forest object
print(RF_obj)

```

A lower CRPS indicates better performance.


```{r Survival curve 90 days}
# Create a hypothetical observation for prediction
# Creating an hypothetical observation 
newdata <- data.frame(lapply(1:ncol(RF_obj$xvar),function(i){median(RF_obj$xvar[,i])}))
colnames(newdata) <- RF_obj$xvar.names

# Predict survival for the hypothetical observation
y.pred <- predict(RF_obj, newdata = rbind(newdata, RF_obj$xvar)[1, ])

# Plot predicted survival probability over time
par(cex.axis = 1.0, cex.lab = 1.0, cex.main = 1.0, mar = c(6.0, 6, 1, 1), mgp = c(4, 1, 0))
plot(
  round(y.pred$time.interest, 2), 
  y.pred$survival[1, ], 
  type = "l", 
  xlab = "Time (Days)", 
  ylab = "Survival Probability", 
  col = 1, 
  lty = 1, 
  lwd = 2, 
  main = "Predicted Survival Curve"
)

```

```{r Brier score 90 days}
# Calculate the Brier score using the Kaplan-Meier censoring distribution
bs.km <- get.brier.survival(RF_obj, cens.mode = "km")$brier.score

# Plot the Brier score
plot(
  bs.km, 
  type = "s", 
  col = 2, 
  ylab = "Brier Score", 
  xlab = "Time (Days)", 
  main = "Brier Score Over Time"
)

```

- < 0.1 - excellent
- <= 0.2 - superior
- <=0.3 - adequate

```{r VIMP 90 days}
# Extract Variable Importance (VIMP)
vimp <- RF_obj$importance

# Convert VIMP to a data frame for easy interpretation
vimp_df <- data.frame(
  Variable = names(vimp),
  VIMP = vimp
)

# Sort variables by VIMP in descending order
vimp_df_positive <- vimp_df %>%
  filter(VIMP > 0) %>%
  arrange(desc(VIMP))

# Plot Variable Importance
ggplot(vimp_df_positive, aes(x = reorder(Variable, VIMP), y = VIMP)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() +
  labs(
    title = "Variable Importance (VIMP) in RSF",
    x = "Variables",
    y = "VIMP"
  ) +
  theme_minimal(base_size = 5)

# Filter for variables with negative VIMP
vimp_negative <- vimp_df %>%
  filter(VIMP < 0) %>%
  arrange(VIMP)  # Sort in ascending order

# Plot variables with negative VIMP
ggplot(vimp_negative, aes(x = reorder(Variable, VIMP), y = VIMP)) +
  geom_bar(stat = "identity", fill = "red") +
  coord_flip() +
  labs(
    title = "Variables with Negative VIMP in RSF",
    x = "Variables",
    y = "VIMP"
  ) +
  theme_minimal(base_size = 6)

```

```{r compare selected featres with boruta algo}
# Compare with VIMP
vimp_boruta_comparison <- vimp_df %>%
  mutate(
    Boruta_Status = case_when(
      Variable %in% important_vars ~ "Confirmed Important",
      Variable %in% tentative_vars ~ "Tentative",
      TRUE ~ "Rejected"
    )
  )

# Filter for top N variables based on absolute VIMP
top_n <- 30  # Adjust this number as needed
vimp_boruta_comparison_filtered <- vimp_boruta_comparison %>%
  arrange(desc(VIMP)) %>%
  head(top_n)

# Plot Comparison for the filtered variables
ggplot(vimp_boruta_comparison_filtered, aes(x = reorder(Variable, VIMP), y = VIMP, fill = Boruta_Status)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  labs(
    title = paste("Top", top_n, "Variables: VIMP and Boruta Comparison"),
    x = "Variables",
    y = "VIMP",
    fill = "Boruta Status"
  ) +
  theme_minimal(base_size = 10) +
  theme(
    legend.position = "bottom",
    plot.title = element_text(face = "bold", hjust = 0.5),
    axis.text.y = element_text(size = 8)
  )

```


### 3.3.5.    Random Forest over Survival
#### 3.3.5.1 90 days

```{r Random Forest over Survival 90 days}

df_cGVHD_prediction_survival <- df_cGVHD_prediction %>%
  mutate(
    cGVHD_Diagnosis_Day = ifelse(is.na(cGVHD_Diagnosis_Day), Observation_Days_Count, cGVHD_Diagnosis_Day),
    cGVHD_flag = as.numeric(as.character(cGVHD_flag))
  ) %>%
  filter(Blood_test_day %in% c("90")) %>%
  filter(cGVHD_Diagnosis_Day > 90 | is.na(cGVHD_Diagnosis_Day)) %>%
  select(-Subject_ID, -Blood_test_day, -Observation_Days_Count)

# Define the dataset
dataSet <- df_cGVHD_prediction_survival %>%
  filter(complete.cases(.))  # Ensure no missing data

```

```{r OOB 90 days}

# Function to evaluate OOB Requested performance error for different numbers of trees
evaluate_trees <- function(data, formula, max_trees = 1000, step = 50) {
  results <- data.frame(Trees = integer(), OOB_Error = numeric())
  
  for (ntree in seq(50, max_trees, by = step)) {
    set.seed(123)  # Ensure reproducibility
    rf_model <- rfsrc(
      formula = formula,
      data = data,
      mtry = round(sqrt(ncol(data) - 2)),
      nodesize = 15,
      ntree = ntree,  # Number of trees
      importance = TRUE
    )
    
    # Extract the OOB Requested performance error
    oob_error <- rf_model$err.rate[length(rf_model$err.rate)]
    results <- rbind(results, data.frame(
      Trees = ntree,
      OOB_Error = oob_error
    ))
  }
  
  return(results)
}

# Apply the function to your dataset
oob_results <- evaluate_trees(
  data = dataSet,  # Replace with your dataset
  formula = Surv(cGVHD_Diagnosis_Day, cGVHD_flag) ~ .,
  max_trees = 1000,
  step = 50
)

ggplot(oob_results, aes(x = Trees, y = OOB_Error)) +
  geom_line() +
  geom_point(size = 2) +
  labs(
    title = "OOB Requested Performance Error vs. Number of Trees",
    x = "Number of Trees",
    y = "OOB Requested Performance Error"
  ) +
  theme_minimal()

# Find the number of trees with the minimum OOB error
best_trees <- oob_results$Trees[which.min(oob_results$OOB_Error)]

print(paste("Best number of trees:", best_trees))
```

```{r RFS 90 days}
# Build the Random Survival Forest model
RF_obj <- rfsrc(Surv(cGVHD_Diagnosis_Day,cGVHD_flag)~.,
                dataSet,
                ntree = best_trees,
                mtry = round(sqrt(ncol(dataSet) - 2)),
                nodesize = 15,
                membership = TRUE,
                importance=TRUE)

# Print the Random Survival Forest object
print(RF_obj)

```

A lower CRPS indicates better performance.

```{r Survival curve 90 days}
# Create a hypothetical observation for prediction
# Creating an hypothetical observation 
newdata <- data.frame(lapply(1:ncol(RF_obj$xvar),function(i){median(RF_obj$xvar[,i])}))
colnames(newdata) <- RF_obj$xvar.names

# Predict survival for the hypothetical observation
y.pred <- predict(RF_obj, newdata = rbind(newdata, RF_obj$xvar)[1, ])

# Plot predicted survival probability over time

plot(
  round(y.pred$time.interest, 2), 
  y.pred$survival[1, ], 
  type = "l", 
  xlab = "Time (Days)", 
  ylab = "Survival Probability", 
  col = 1, 
  lty = 1, 
  lwd = 2, 
  main = "Predicted Survival Curve"
)

```

```{r Brier score 180 days}
# Calculate the Brier score using the Kaplan-Meier censoring distribution
bs.km <- get.brier.survival(RF_obj, cens.mode = "km")$brier.score

# Plot the Brier score
plot(
  bs.km, 
  type = "s", 
  col = 2, 
  ylab = "Brier Score", 
  xlab = "Time (Days)", 
  main = "Brier Score Over Time"
)

```

- < 0.1 - excellent
- <= 0.2 - superior
- <=0.3 - adequate

```{r VIMP 90 days}
# Extract Variable Importance (VIMP)
vimp <- RF_obj$importance

# Convert VIMP to a data frame for easy interpretation
vimp_df <- data.frame(
  Variable = names(vimp),
  VIMP = vimp
)

# Sort variables by VIMP in descending order
vimp_df_positive <- vimp_df %>%
  filter(VIMP > 0) %>%
  arrange(desc(VIMP)) %>%
  head(30)

# Plot Variable Importance
ggplot(vimp_df_positive, aes(x = reorder(Variable, VIMP), y = VIMP)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() +
  labs(
    title = "Variable Importance (VIMP) in RSF",
    x = "Variables",
    y = "VIMP"
  ) +
  theme_minimal(base_size = 8)

# Filter for variables with negative VIMP
vimp_negative <- vimp_df %>%
  filter(VIMP < 0) %>%
  arrange(VIMP)  # Sort in ascending order

# Plot variables with negative VIMP
ggplot(vimp_negative, aes(x = reorder(Variable, VIMP), y = VIMP)) +
  geom_bar(stat = "identity", fill = "red") +
  coord_flip() +
  labs(
    title = "Variables with Negative VIMP in RSF",
    x = "Variables",
    y = "VIMP"
  ) +
  theme_minimal(base_size = 4)

```

```{r VIMP vs Boruta 90 days}
# Compare with VIMP
vimp_boruta_comparison <- vimp_df_positive %>%
  mutate(
    Boruta_Status = case_when(
      Variable %in% important_vars_90 ~ "Confirmed Important",
      Variable %in% tentative_vars_90 ~ "Tentative",
      TRUE ~ "Rejected"
    )
  )

# Plot Comparison
ggplot(vimp_boruta_comparison, aes(x = reorder(Variable, VIMP), y = VIMP, fill = Boruta_Status)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  labs(
    title = "VIMP and Boruta Comparison",
    x = "Variables",
    y = "VIMP",
    fill = "Boruta Status"
  ) +
  theme_minimal(base_size = 8)

# Print Final Comparison Table
print(vimp_boruta_comparison)

```

#### 3.3.5.2 180 days

```{r Random Forest over Survival 180 days}

df_cGVHD_prediction_survival <- df_cGVHD_prediction %>%
  mutate(
    cGVHD_Diagnosis_Day = ifelse(is.na(cGVHD_Diagnosis_Day), Observation_Days_Count, cGVHD_Diagnosis_Day),
    cGVHD_flag = as.numeric(as.character(cGVHD_flag))
  ) %>%
  select(-Observation_Days_Count) %>%
  filter(Blood_test_day %in% c("180")) %>%
  filter(cGVHD_Diagnosis_Day > 180 | is.na(cGVHD_Diagnosis_Day)) %>%
  select(-Subject_ID, -Blood_test_day)

# Define the dataset
dataSet <- df_cGVHD_prediction_survival %>%
  filter(complete.cases(.))  # Ensure no missing data

```

```{r OOB 180 days}

# Function to evaluate OOB Requested performance error for different numbers of trees
evaluate_trees <- function(data, formula, max_trees = 1000, step = 50) {
  results <- data.frame(Trees = integer(), OOB_Error = numeric())
  
  for (ntree in seq(50, max_trees, by = step)) {
    set.seed(123)  # Ensure reproducibility
    rf_model <- rfsrc(
      formula = formula,
      data = data,
      mtry = round(sqrt(ncol(data) - 2)),
      nodesize = 15,
      ntree = ntree,  # Number of trees
      importance = TRUE
    )
    
    # Extract the OOB Requested performance error
    oob_error <- rf_model$err.rate[length(rf_model$err.rate)]
    results <- rbind(results, data.frame(
      Trees = ntree,
      OOB_Error = oob_error
    ))
  }
  
  return(results)
}

# Apply the function to your dataset
oob_results <- evaluate_trees(
  data = dataSet,  # Replace with your dataset
  formula = Surv(cGVHD_Diagnosis_Day, cGVHD_flag) ~ .,
  max_trees = 1000,
  step = 50
)

ggplot(oob_results, aes(x = Trees, y = OOB_Error)) +
  geom_line() +
  geom_point(size = 2) +
  labs(
    title = "OOB Requested Performance Error vs. Number of Trees",
    x = "Number of Trees",
    y = "OOB Requested Performance Error"
  ) +
  theme_minimal()

# Find the number of trees with the minimum OOB error
best_trees <- oob_results$Trees[which.min(oob_results$OOB_Error)]

print(paste("Best number of trees:", best_trees))
```



```{r RFS 180 days}
# Build the Random Survival Forest model
RF_obj <- rfsrc(Surv(cGVHD_Diagnosis_Day,cGVHD_flag)~.,
                dataSet,
                ntree = best_trees,
                mtry = round(sqrt(ncol(dataSet) - 2)),
                nodesize = 15,
                membership = TRUE,
                importance=TRUE)

# Print the Random Survival Forest object
print(RF_obj)

```

A lower CRPS indicates better performance.


```{r Survival curve 180 days}
# Create a hypothetical observation for prediction
# Creating an hypothetical observation 
newdata <- data.frame(lapply(1:ncol(RF_obj$xvar),function(i){median(RF_obj$xvar[,i])}))
colnames(newdata) <- RF_obj$xvar.names

# Predict survival for the hypothetical observation
y.pred <- predict(RF_obj, newdata = rbind(newdata, RF_obj$xvar)[1, ])

# Plot predicted survival probability over time

plot(
  round(y.pred$time.interest, 2), 
  y.pred$survival[1, ], 
  type = "l", 
  xlab = "Time (Days)", 
  ylab = "Survival Probability", 
  col = 1, 
  lty = 1, 
  lwd = 2, 
  main = "Predicted Survival Curve"
)

```

```{r Brier score 180 days}
# Calculate the Brier score using the Kaplan-Meier censoring distribution
bs.km <- get.brier.survival(RF_obj, cens.mode = "km")$brier.score

# Plot the Brier score
plot(
  bs.km, 
  type = "s", 
  col = 2, 
  ylab = "Brier Score", 
  xlab = "Time (Days)", 
  main = "Brier Score Over Time"
)

```

- < 0.1 - excellent
- <= 0.2 - superior
- <= 0.3 - adequate

```{r VIMP 180 days}
# Extract Variable Importance (VIMP)
vimp <- RF_obj$importance

# Convert VIMP to a data frame for easy interpretation
vimp_df <- data.frame(
  Variable = names(vimp),
  VIMP = vimp
)

# Sort variables by VIMP in descending order
vimp_df_positive <- vimp_df %>%
  filter(VIMP > 0) %>%
  arrange(desc(VIMP)) %>%
  head(30)

# Plot Variable Importance
ggplot(vimp_df_positive, aes(x = reorder(Variable, VIMP), y = VIMP)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() +
  labs(
    title = "Variable Importance (VIMP) in RSF",
    x = "Variables",
    y = "VIMP"
  ) +
  theme_minimal(base_size = 8)

# Filter for variables with negative VIMP
vimp_negative <- vimp_df %>%
  filter(VIMP < 0) %>%
  arrange(VIMP)  # Sort in ascending order

# Plot variables with negative VIMP
ggplot(vimp_negative, aes(x = reorder(Variable, VIMP), y = VIMP)) +
  geom_bar(stat = "identity", fill = "red") +
  coord_flip() +
  labs(
    title = "Variables with Negative VIMP in RSF",
    x = "Variables",
    y = "VIMP"
  ) +
  theme_minimal(base_size = 4)

```



```{r VIMP vs Boruta 180 days}

# Compare with VIMP
vimp_boruta_comparison <- vimp_df_positive %>%
  mutate(
    Boruta_Status = case_when(
      Variable %in% important_vars_180 ~ "Confirmed Important",
      Variable %in% only_tentative_vars_180 ~ "Tentative",
      TRUE ~ "Rejected"
    )
  )

# Plot Comparison
ggplot(vimp_boruta_comparison, aes(x = reorder(Variable, VIMP), y = VIMP, fill = Boruta_Status)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  labs(
    title = "VIMP and Boruta Comparison",
    x = "Variables",
    y = "VIMP",
    fill = "Boruta Status"
  ) +
  theme_minimal(base_size = 8)

# Print Final Comparison Table
print(vimp_boruta_comparison)

```

#### 3.3.5.3 365 days

```{r Random Forest over Survival 365 days}

df_cGVHD_prediction_survival <- df_cGVHD_prediction %>%
  mutate(
    cGVHD_Diagnosis_Day = ifelse(is.na(cGVHD_Diagnosis_Day), Observation_Days_Count, cGVHD_Diagnosis_Day),
    
    Blood_test_day = ifelse(Blood_test_day == "cGVHD", cGVHD_Diagnosis_Day, Blood_test_day),
    Blood_test_day = as.numeric(as.character(Blood_test_day)),
    cGVHD_flag = as.numeric(as.character(cGVHD_flag))
  ) %>%
  select(-Observation_Days_Count) %>%
  filter(Blood_test_day %in% c("365")) %>%
  filter(cGVHD_Diagnosis_Day > 365 | is.na(cGVHD_Diagnosis_Day)) %>%
  select(-Subject_ID, -Blood_test_day)

# Define the dataset
dataSet <- df_cGVHD_prediction_survival %>%
  filter(complete.cases(.))  # Ensure no missing data

```

```{r OOB 365 days}

# Function to evaluate OOB Requested performance error for different numbers of trees
evaluate_trees <- function(data, formula, max_trees = 1000, step = 20) {
  results <- data.frame(Trees = integer(), OOB_Error = numeric())
  
  for (ntree in seq(20, max_trees, by = step)) {
    set.seed(123)  # Ensure reproducibility
    rf_model <- rfsrc(
      formula = formula,
      data = data,
      mtry = round(sqrt(ncol(data) - 2)),
      nodesize = 15,
      ntree = ntree,  # Number of trees
      importance = TRUE
    )
    
    # Extract the OOB Requested performance error
    oob_error <- rf_model$err.rate[length(rf_model$err.rate)]
    results <- rbind(results, data.frame(
      Trees = ntree,
      OOB_Error = oob_error
    ))
  }
  
  return(results)
}

# Apply the function to your dataset
oob_results <- evaluate_trees(
  data = dataSet,  # Replace with your dataset
  formula = Surv(cGVHD_Diagnosis_Day, cGVHD_flag) ~ .,
  max_trees = 1000,
  step = 50
)

ggplot(oob_results, aes(x = Trees, y = OOB_Error)) +
  geom_line() +
  geom_point(size = 2) +
  labs(
    title = "OOB Requested Performance Error vs. Number of Trees",
    x = "Number of Trees",
    y = "OOB Requested Performance Error"
  ) +
  theme_minimal()

# Find the number of trees with the minimum OOB error
best_trees <- oob_results$Trees[which.min(oob_results$OOB_Error)]

print(paste("Best number of trees:", best_trees))
```



# 4. Diagnostics of cGVHD

Comparison on the day of the onset of chronic GVHD with the closest points in terms of timing in patients without chronic GVHD.

*Group 1:* Patients diagnosed with cGVHD (cGVHD_flag = 1).
*Group 2: *Patients without cGVHD (cGVHD_flag = 0).

- For Group 1, will be used data from the day of cGVHD onset (cGVHD_Diagnosis_Day).
- For Group 2, the closest time point to the median diagnosis day of Group 1 (Median_Diagnosis_Day) is 180 days.

Due to large ammount of immune cell markers (332):

1. Cluster immune cell markers to identify groups of similar variables.
2. After clustering, perform statistical comparisons for clasters.

## 4.1. Define Data

``` {r Diagnostics of cGVHD choose the second group }
# Plot the density plot for cGVHD Diagnosis Day
df_transformed %>%
  filter(cGVHD_flag == 1) %>%
  ggplot(aes(x = cGVHD_Diagnosis_Day)) +
  geom_density(fill = "blue", alpha = 0.7) +
  theme_minimal() +
  labs(
    title = "Distribution of cGVHD Diagnosis Day",
    x = "cGVHD Diagnosis Day",
    y = "Density"
  )

```

# 5. Immunological Profiles of Patients with or without cGVHD


